{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imsave, imread\n",
    "from skimage import img_as_ubyte, img_as_float\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_pair(im, gdt, vmin1=None, vmax1=None, vmin2=None, vmax2=None):\n",
    "    f, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "    np_im = np.asarray(im)\n",
    "    np_gdt = np.asarray(gdt)\n",
    "    if len(np_im.shape) == 2:\n",
    "        if vmin1==None:\n",
    "            ax[0].imshow(np_im, cmap='gray'),  ax[0].axis('off')\n",
    "        else:\n",
    "            ax[0].imshow(np_im, cmap='gray', vmin=vmin1, vmax=vmax1),  ax[0].axis('off')\n",
    "    else:\n",
    "        ax[0].imshow(np_im),  ax[0].axis('off')\n",
    "    if len(np_gdt.shape) == 2:\n",
    "        if vmin2==None:\n",
    "            ax[1].imshow(np.asarray(gdt), cmap = 'gray'), ax[1].axis('off')\n",
    "\n",
    "        else:\n",
    "            ax[1].imshow(np.asarray(gdt), cmap = 'gray', vmin=vmin2, vmax=vmax2), ax[1].axis('off')            \n",
    "    else:\n",
    "        ax[1].imshow(np.asarray(gdt)), ax[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from skimage.color import label2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "dice_metric = DiceMetric(mutually_exclusive=True, to_onehot_y=True, reduction='none', include_background=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "\n",
    "def evaluate(logits, labels):\n",
    "    all_targets = []\n",
    "    all_probs_0 = []\n",
    "    all_probs_1 = []\n",
    "    all_probs_2 = []\n",
    "\n",
    "    for i in range(len(logits)):\n",
    "        probs = torch.nn.Softmax(dim=0)(logits[i]).detach().cpu().numpy()\n",
    "        all_probs_0.extend(probs[0].ravel())\n",
    "        all_probs_1.extend(probs[1].ravel())\n",
    "        all_probs_2.extend(probs[2].ravel())\n",
    "\n",
    "        target = labels[i].numpy()\n",
    "\n",
    "        all_targets.append(target.ravel())\n",
    "\n",
    "    all_probs_np = np.stack([all_probs_0, all_probs_1, all_probs_2], axis=1)\n",
    "    all_preds_np = np.argmax(all_probs_np, axis=1)\n",
    "    \n",
    "    all_targets_np = np.hstack(all_targets)\n",
    "    all_preds_np = 1+all_preds_np # we are predicting only three classes and ignoring background\n",
    "    all_preds_np[all_targets_np==0]=0\n",
    "    \n",
    "    return f1_score(all_targets_np, all_preds_np,average='weighted', labels=[1,2,3]), \\\n",
    "            mcc(all_targets_np[all_targets_np!=0], all_preds_np[all_targets_np!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets\n",
    "\n",
    "With a data source and transforms defined we can now create a dataset object. The base class for MONAI is `Dataset`, created here to load the image files only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.get_loaders import get_train_val_loaders\n",
    "\n",
    "train_loader, val_loader = get_train_val_loaders(csv_path_train='data/DRIVE/train_av.csv', \n",
    "                                                 csv_path_val='data/DRIVE/val_av.csv', batch_size=4,\n",
    "                                                 tg_size=(512,512), label_values=[0, 85, 170, 255], \n",
    "                                                 num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dice_loss import SimilarityLoss\n",
    "sim_loss = SimilarityLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TvLoss(torch.nn.Module):\n",
    "    def __init__(self, ignore_background=True, reduction='mean'):\n",
    "        super(TvLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.ignore_background = ignore_background\n",
    "\n",
    "    def compute_tv(self, logits, labels):\n",
    "\n",
    "        probs = torch.nn.Softmax(dim=1)(logits)\n",
    "        labels_oh = torch.cat([labels==0, labels==1, labels==2, labels==3], dim=1).long()\n",
    "\n",
    "        probs = torch.mul(probs, labels_oh) # discard values outside labels\n",
    "\n",
    "    #     foreground = torch.cat([labels!=0, labels!=0, labels!=0, labels!=0], dim=1).long()\n",
    "    #     probs_filtered = torch.mul(probs, foreground) # discard values outside vessels\n",
    "\n",
    "        tv_l = torch.abs(torch.sub(probs, torch.roll(probs, shifts=1, dims=-1)))\n",
    "        tv_r = torch.abs(torch.sub(probs, torch.roll(probs, shifts=-1, dims=-1)))\n",
    "\n",
    "        tv_u = torch.abs(torch.sub(probs, torch.roll(probs, shifts=-1, dims=-2)))\n",
    "        tv_d = torch.abs(torch.sub(probs, torch.roll(probs, shifts=1, dims=-2)))\n",
    "    #     tv_d = torch.clamp(tv_d, min=0, max=1)\n",
    "\n",
    "        tv = torch.mean(torch.stack([tv_l, tv_r, tv_u, tv_d], axis=0), dim=0)\n",
    "\n",
    "        return tv\n",
    "    \n",
    "    def forward(self, logits, labels):\n",
    "        probs = torch.nn.Softmax(dim=1)(logits)\n",
    "        labels_oh = torch.cat([labels==0, labels==1, labels==2, labels==3], dim=1).float()\n",
    "        \n",
    "        tv = self.compute_tv(logits, labels)\n",
    "        \n",
    "        perfect_tv = self.compute_tv(100*labels_oh, labels)>0\n",
    "        tv[perfect_tv]=0\n",
    "        \n",
    "        tv = torch.div(tv, probs+1e-6)\n",
    "        \n",
    "       \n",
    "        mean_per_elem_per_class = (tv.sum(dim=(-2, -1)) / (labels_oh.sum(dim=(-2, -1))+1e-6)  )\n",
    "        mean_per_class = mean_per_elem_per_class.mean(dim=0)\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return mean_per_class[2:].mean()\n",
    "        elif self.reduction == 'per_class':\n",
    "            return mean_per_class[2:]\n",
    "        elif self.reduction == 'per_elem_per_class':\n",
    "            return mean_per_elem_per_class[:, 2:]\n",
    "        elif self.reduction == 'none':\n",
    "            return tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_criterion = TvLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_one_epoch(loader, model, criterion, optimizer=None, scheduler=None,\n",
    "                  grad_acc_steps=0, assess=False, save_plot=False, cycle=0):\n",
    "    device='cuda' if next(model.parameters()).is_cuda else 'cpu'\n",
    "    train = optimizer is not None  # if we are in training mode there will be an optimizer and train=True here\n",
    "\n",
    "    if train: model.train()\n",
    "    else: model.eval()\n",
    "        \n",
    "    if assess: dice_unc, dice_arteries, dice_veins, f1_scs, mcc_scs = 0, 0, 0, [], []\n",
    "    n_elems, running_loss, tv_running_loss = 0, 0, 0\n",
    "    wnet=False\n",
    "    for i_batch, batch_data in enumerate(loader):\n",
    "        try:\n",
    "            inputs, labels = (batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device), )\n",
    "        except:\n",
    "            inputs, labels = batch_data[0].to(device), batch_data[1].unsqueeze(dim=1).to(device)\n",
    "            \n",
    "            \n",
    "        if train:  # only in training mode               \n",
    "            logits = model(inputs)\n",
    "            if isinstance(logits, tuple): # wnet\n",
    "                wnet=True\n",
    "                logits_aux, logits = logits              \n",
    "                loss_aux = criterion(torch.cat([-10*torch.ones(labels.shape).to(device), \n",
    "                                              logits_aux], dim=1), labels.squeeze(dim=1))\n",
    "            loss = criterion(torch.cat([-10*torch.ones(labels.shape).to(device), logits], dim=1), labels.squeeze())\n",
    "            \n",
    "            tv_loss= 10*tv_criterion(torch.cat([-10*torch.ones(labels.shape).to(device), logits], dim=1), labels)\n",
    "                       \n",
    "            \n",
    "            if wnet:\n",
    "                loss+=loss_aux\n",
    "            \n",
    "            \n",
    "            ( (loss+0.1*tv_loss) / (grad_acc_steps + 1)).backward()\n",
    "#             ( (loss) / (grad_acc_steps + 1)).backward()\n",
    "        \n",
    "            if i_batch % (grad_acc_steps+1) == 0:  # for grad_acc_steps=0, this is always True\n",
    "                optimizer.step()\n",
    "                for _ in range(grad_acc_steps+1): scheduler.step() # for grad_acc_steps=0, this means once\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        else:\n",
    "            logits = model(inputs)\n",
    "            if isinstance(logits, tuple): # wnet\n",
    "                wnet=True\n",
    "                logits_aux, logits = logits\n",
    "                loss_aux = criterion(torch.cat([-10*torch.ones(labels.shape).to(device), \n",
    "                                              logits_aux], dim=1), labels.squeeze(dim=1))\n",
    "            loss = criterion(torch.cat([-10*torch.ones(labels.shape).to(device), logits], dim=1), labels.squeeze())\n",
    "            tv_loss= 10*tv_criterion(torch.cat([-10*torch.ones(labels.shape).to(device), logits], dim=1), labels)\n",
    "            \n",
    "            if wnet:\n",
    "                loss+=loss_aux\n",
    "\n",
    "            if assess:\n",
    "                dice_unc, dice_arteries, dice_veins = \\\n",
    "                dice_metric(torch.cat([-10*torch.ones(labels.shape).to(device), logits], dim=1), labels).mean(dim=0)\n",
    "                \n",
    "                if save_plot:\n",
    "                    preds = torch.argmax(logits,dim=1)+1\n",
    "                    back=labels==0\n",
    "                    preds[back.squeeze()]=0.5\n",
    "                    for j in range(logits.shape[0]):\n",
    "                        from skimage.color import label2rgb\n",
    "                        rgb_pred = label2rgb(preds[j].cpu().numpy(), colors=['black', 'green', 'red', 'blue'])\n",
    "                        rgb_labels = label2rgb(labels[j].squeeze().cpu().numpy(), colors=['black', 'green', 'red', 'blue'])\n",
    "#                         f=imshow_pair(preds[j].cpu(), labels[j].squeeze().cpu())\n",
    "                        f=imshow_pair(rgb_pred, rgb_labels)\n",
    "#                         f.savefig(s_name)\n",
    "#                         plt.close(f)\n",
    "                \n",
    "                f1_s, mcc_s = evaluate(logits.detach().cpu(), labels.cpu())\n",
    "                f1_scs.append(f1_s)\n",
    "                mcc_scs.append(mcc_s)\n",
    "        # Compute running loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        tv_running_loss += tv_loss.item() * inputs.size(0)\n",
    "        n_elems += inputs.size(0)\n",
    "        run_loss = running_loss / n_elems\n",
    "        tv_run_loss = tv_running_loss / n_elems\n",
    "            \n",
    "    if assess: return dice_unc, dice_arteries, dice_veins, \\\n",
    "                      np.array(f1_scs).mean(), np.array(mcc_scs).mean(), run_loss, tv_run_loss\n",
    "    return None, None, None, None, None, run_loss, tv_run_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_one_cycle(train_loader, model, criterion, optimizer=None, scheduler=None, grad_acc_steps=0, cycle=0):\n",
    "    # prepare next cycle:\n",
    "    # reset iteration counter\n",
    "    scheduler.last_epoch = -1\n",
    "    # update number of iterations\n",
    "\n",
    "    scheduler.T_max = scheduler.cycle_lens[cycle] * len(train_loader)\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    cycle_len = scheduler.cycle_lens[cycle]\n",
    "    with trange(cycle_len) as t:\n",
    "        for epoch in range(cycle_len):\n",
    "            if epoch == cycle_len-1: assess=True # only compute performance on last epoch\n",
    "            else: assess = False\n",
    "\n",
    "            d_bck, d_arts, d_veins, \\\n",
    "            f1_sc, mcc_sc, tr_loss, tr_tv_loss = run_one_epoch(train_loader, model, criterion, optimizer=optimizer,\n",
    "                                                          scheduler=scheduler, grad_acc_steps=grad_acc_steps, \n",
    "                                                          assess=assess, cycle=cycle)\n",
    "            t.set_postfix_str(\"Cycle: {}/{} Ep. {}/{} -- tr. loss={:.4f}|{:.4f} / lr={:.6f}\".format(cycle+1, \n",
    "                                                                                    len(scheduler.cycle_lens),\n",
    "                                                                                    epoch+1, cycle_len,\n",
    "                                                                                    float(tr_loss), \n",
    "                                                                                    float(tr_tv_loss), \n",
    "                                                                                    get_lr(optimizer)))\n",
    "            t.update()\n",
    "    return d_bck, d_arts, d_veins, f1_sc, mcc_sc, tr_loss, tr_tv_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV LOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_classes=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68678"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.res_unet_adrian import UNet as unet\n",
    "\n",
    "class Wnet(torch.nn.Module):\n",
    "    def __init__(self, n_classes=1, in_c=3, layers=(8, 16, 32), conv_bridge=True, shortcut=True, mode='train'):\n",
    "        super(Wnet, self).__init__()\n",
    "        self.mode=mode\n",
    "        self.unet1 = unet(in_c=in_c, n_classes=n_classes, layers=layers, conv_bridge=conv_bridge, shortcut=shortcut)\n",
    "        self.unet2 = unet(in_c=in_c+n_classes, n_classes=n_classes, layers=layers, conv_bridge=conv_bridge, shortcut=shortcut)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.unet1(x)\n",
    "        x2 = self.unet2(torch.cat([x, x1], dim=1))\n",
    "        if self.mode!='train':\n",
    "            return x2\n",
    "        return x1,x2\n",
    "\n",
    "model = Wnet(in_c=3, n_classes=n_classes, layers=[8,16,32])\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "model.to(device);\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.model_saving_loading import load_model\n",
    "# model, stats = load_model(model, 'experiments/BASELINE/', 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cycle_lens = [20, 50]\n",
    "grad_acc_steps=0\n",
    "n_cycles = cycle_lens[0]\n",
    "min_lr = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = bb[0], bb[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = model(x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits_aux, logits = logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(cycle_lens)==2: # handles option of specifying cycles as pair (n_cycles, cycle_len)\n",
    "    cycle_lens = cycle_lens[0]*[cycle_lens[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 1e-2)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                              T_max=cycle_lens[0] * len(train_loader) // (grad_acc_steps + 1), \n",
    "                              eta_min=min_lr)\n",
    "setattr(scheduler, 'cycle_lens', cycle_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [00:54<00:01,  1.11s/it, Cycle: 1/20 Ep. 49/50 -- tr. loss=0.7305|0.1039 / lr=0.000015]Mean of empty slice.\n",
      "100%|██████████| 50/50 [00:55<00:00,  1.12s/it, Cycle: 1/20 Ep. 50/50 -- tr. loss=0.7124|0.0955 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.7550/0.8098 -- Train/Val TV Loss: 0.1010/0.1276\n",
      "Train/Val F1|MCC: 0.8635/0.8461 | 0.7363/0.6992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:55<00:00,  1.11s/it, Cycle: 2/20 Ep. 50/50 -- tr. loss=0.7048|0.0942 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.7452/0.7951 -- Train/Val TV Loss: 0.1018/0.1197\n",
      "Train/Val F1|MCC: 0.8697/0.8502 | 0.7486/0.7084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:55<00:00,  1.12s/it, Cycle: 3/20 Ep. 50/50 -- tr. loss=0.6708|0.0832 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.6913/0.7891 -- Train/Val TV Loss: 0.0894/0.1208\n",
      "Train/Val F1|MCC: 0.8838/0.8528 | 0.7752/0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:55<00:00,  1.12s/it, Cycle: 4/20 Ep. 50/50 -- tr. loss=0.6952|0.0929 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.7814/0.8404 -- Train/Val TV Loss: 0.1095/0.1312\n",
      "Train/Val F1|MCC: 0.8631/0.8385 | 0.7357/0.6849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:13<00:42,  1.11s/it, Cycle: 5/20 Ep. 12/50 -- tr. loss=0.7390|0.1089 / lr=0.008698]"
     ]
    }
   ],
   "source": [
    "for cycle in range(10):\n",
    "\n",
    "    _, _, _, _, _, _, _ = train_one_cycle(train_loader,model, criterion, optimizer,scheduler,cycle=cycle)\n",
    "\n",
    "    save_plot = (cycle+1)%5==0\n",
    "    save_plot=False\n",
    "    with torch.no_grad():\n",
    "        _, _, _, tr_f1, tr_mcc, tr_loss, tr_tv_loss = run_one_epoch(train_loader, model, criterion, \n",
    "                                                                 optimizer=None, scheduler=None,\n",
    "                                                                 grad_acc_steps=0, assess=True, \n",
    "                                                                 save_plot=save_plot, cycle=cycle)\n",
    "        \n",
    "        _, _, _, vl_f1, vl_mcc, vl_loss, vl_tv_loss = run_one_epoch(val_loader, model, criterion, \n",
    "                                                                 optimizer=None, scheduler=None,\n",
    "                                                                 grad_acc_steps=0, assess=True, \n",
    "                                                                 save_plot=save_plot, cycle=cycle)\n",
    "\n",
    "        \n",
    "        print('Train/Val Loss: {:.4f}/{:.4f} -- '\\\n",
    "              'Train/Val TV Loss: {:.4f}/{:.4f}'.format(tr_loss, vl_loss, tr_tv_loss, vl_tv_loss))\n",
    "        print('Train/Val F1|MCC: {:.4f}/{:.4f} | {:.4f}/{:.4f}'.format(tr_f1, vl_f1, tr_mcc, vl_mcc))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [00:52<00:01,  1.09s/it, Cycle: 1/20 Ep. 49/50 -- tr. loss=0.8626|0.1655 / lr=0.000015]Mean of empty slice.\n",
      "100%|██████████| 50/50 [00:53<00:00,  1.08s/it, Cycle: 1/20 Ep. 50/50 -- tr. loss=0.8471|0.1588 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.8622/0.8072 -- Train/Val TV Loss: 0.1621/0.1526\n",
      "Train/Val F1|MCC: 0.8260/0.8462 | 0.6641/0.7008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.09s/it, Cycle: 2/20 Ep. 50/50 -- tr. loss=0.8239|0.1589 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.8419/0.8351 -- Train/Val TV Loss: 0.1620/0.1724\n",
      "Train/Val F1|MCC: 0.8326/0.8396 | 0.6759/0.6873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.09s/it, Cycle: 3/20 Ep. 50/50 -- tr. loss=0.8370|0.1538 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.8641/0.7777 -- Train/Val TV Loss: 0.1689/0.1483\n",
      "Train/Val F1|MCC: 0.8316/0.8526 | 0.6747/0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.08s/it, Cycle: 4/20 Ep. 50/50 -- tr. loss=0.8166|0.1454 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.8048/0.7932 -- Train/Val TV Loss: 0.1495/0.1570\n",
      "Train/Val F1|MCC: 0.8474/0.8483 | 0.7067/0.7044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.09s/it, Cycle: 5/20 Ep. 50/50 -- tr. loss=0.8119|0.1604 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.7490/0.7821 -- Train/Val TV Loss: 0.1308/0.1585\n",
      "Train/Val F1|MCC: 0.8625/0.8591 | 0.7342/0.7252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.09s/it, Cycle: 6/20 Ep. 50/50 -- tr. loss=0.7867|0.1469 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.8137/0.7965 -- Train/Val TV Loss: 0.1491/0.1682\n",
      "Train/Val F1|MCC: 0.8458/0.8526 | 0.7012/0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.09s/it, Cycle: 7/20 Ep. 50/50 -- tr. loss=0.7472|0.1373 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.7764/0.8032 -- Train/Val TV Loss: 0.1424/0.1645\n",
      "Train/Val F1|MCC: 0.8546/0.8516 | 0.7194/0.7107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.09s/it, Cycle: 8/20 Ep. 50/50 -- tr. loss=0.7233|0.1230 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.7572/0.7748 -- Train/Val TV Loss: 0.1294/0.1550\n",
      "Train/Val F1|MCC: 0.8584/0.8586 | 0.7257/0.7239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.08s/it, Cycle: 9/20 Ep. 50/50 -- tr. loss=0.7039|0.1233 / lr=0.000001]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.7411/0.7729 -- Train/Val TV Loss: 0.1326/0.1563\n",
      "Train/Val F1|MCC: 0.8668/0.8565 | 0.7426/0.7199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.09s/it, Cycle: 10/20 Ep. 50/50 -- tr. loss=0.6871|0.1181 / lr=0.000001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Loss: 0.7350/0.7941 -- Train/Val TV Loss: 0.1340/0.1638\n",
      "Train/Val F1|MCC: 0.8621/0.8532 | 0.7329/0.7133\n"
     ]
    }
   ],
   "source": [
    "for cycle in range(10):\n",
    "\n",
    "    _, _, _, _, _, _, _ = train_one_cycle(train_loader,model, criterion, optimizer,scheduler,cycle=cycle)\n",
    "\n",
    "    save_plot = (cycle+1)%5==0\n",
    "    save_plot=False\n",
    "    with torch.no_grad():\n",
    "        _, _, _, tr_f1, tr_mcc, tr_loss, tr_tv_loss = run_one_epoch(train_loader, model, criterion, \n",
    "                                                                 optimizer=None, scheduler=None,\n",
    "                                                                 grad_acc_steps=0, assess=True, \n",
    "                                                                 save_plot=save_plot, cycle=cycle)\n",
    "        \n",
    "        _, _, _, vl_f1, vl_mcc, vl_loss, vl_tv_loss = run_one_epoch(val_loader, model, criterion, \n",
    "                                                                 optimizer=None, scheduler=None,\n",
    "                                                                 grad_acc_steps=0, assess=True, \n",
    "                                                                 save_plot=save_plot, cycle=cycle)\n",
    "\n",
    "        \n",
    "        print('Train/Val Loss: {:.4f}/{:.4f} -- '\\\n",
    "              'Train/Val TV Loss: {:.4f}/{:.4f}'.format(tr_loss, vl_loss, tr_tv_loss, vl_tv_loss))\n",
    "        print('Train/Val F1|MCC: {:.4f}/{:.4f} | {:.4f}/{:.4f}'.format(tr_f1, vl_f1, tr_mcc, vl_mcc))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    vl_d_unc, vl_d_arts, vl_d_veins, vl_f1, vl_mcc, tr_loss = run_one_epoch(val_loader, model, criterion, \n",
    "                                                             optimizer=None, scheduler=None,\n",
    "                                                             grad_acc_steps=0, assess=True, \n",
    "                                                             save_plot=True, cycle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vl_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,labels = next(iter(train_loader))\n",
    "labels=labels.unsqueeze(dim=1)\n",
    "x.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(x.to(device))\n",
    "del x\n",
    "logits_aux, logits_pre = logits\n",
    "logits_aux, logits_pre = logits_aux.cpu(), logits_pre.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_pre.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TvLoss(torch.nn.Module):\n",
    "    def __init__(self, ignore_background=True, reduction='mean'):\n",
    "        super(TvLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.ignore_background = ignore_background\n",
    "\n",
    "    def compute_tv(self, logits, labels):\n",
    "\n",
    "        probs = torch.nn.Softmax(dim=1)(logits)\n",
    "        labels_oh = torch.cat([labels==0, labels==1, labels==2, labels==3], dim=1).long()\n",
    "\n",
    "        probs = torch.mul(probs, labels_oh) # discard values outside labels\n",
    "\n",
    "    #     foreground = torch.cat([labels!=0, labels!=0, labels!=0, labels!=0], dim=1).long()\n",
    "    #     probs_filtered = torch.mul(probs, foreground) # discard values outside vessels\n",
    "\n",
    "        tv_l = torch.abs(torch.sub(probs, torch.roll(probs, shifts=1, dims=-1)))\n",
    "        tv_r = torch.abs(torch.sub(probs, torch.roll(probs, shifts=-1, dims=-1)))\n",
    "\n",
    "        tv_u = torch.abs(torch.sub(probs, torch.roll(probs, shifts=-1, dims=-2)))\n",
    "        tv_d = torch.abs(torch.sub(probs, torch.roll(probs, shifts=1, dims=-2)))\n",
    "    #     tv_d = torch.clamp(tv_d, min=0, max=1)\n",
    "\n",
    "        tv = torch.mean(torch.stack([tv_l, tv_r, tv_u, tv_d], axis=0), dim=0)\n",
    "\n",
    "        return tv\n",
    "    \n",
    "    def forward(self, logits, labels):\n",
    "        probs = torch.nn.Softmax(dim=1)(logits)\n",
    "        labels_oh = torch.cat([labels==0, labels==1, labels==2, labels==3], dim=1).float()\n",
    "        \n",
    "        tv = self.compute_tv(logits, labels)\n",
    "        \n",
    "        perfect_tv = compute_tv(100*labels_oh, labels)>0\n",
    "        tv[perfect_tv]=0\n",
    "        \n",
    "        tv = torch.div(tv, probs+1e-6)\n",
    "        \n",
    "       \n",
    "        mean_per_elem_per_class = (tv.sum(dim=(-2, -1)) / (labels_oh.sum(dim=(-2, -1))+1e-6)  )\n",
    "        mean_per_class = mean_per_elem_per_class.mean(dim=0)\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return mean_per_class[1:].mean()\n",
    "        elif self.reduction == 'per_class':\n",
    "            return mean_per_class[1:]\n",
    "        elif self.reduction == 'per_elem_per_class':\n",
    "            return mean_per_elem_per_class[:, 1:]\n",
    "        elif self.reduction == 'none':\n",
    "            return tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_loss = TvLoss(reduction='none')\n",
    "tv_loss_r = TvLoss(reduction='per_elem_per_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = tv_loss(logits, labels)\n",
    "tv.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb=1\n",
    "imshow_pair(labels_oh[bb,2,50:300,10+250:10+400], labels_oh[bb,3,50:300,10+250:10+400], vmin1=0,vmax1=1);\n",
    "imshow_pair(probs_filtered[bb,2,50:300,10+250:10+400], probs_filtered[bb,3,50:300,10+250:10+400], vmin1=0,vmax1=1, vmin2=0,vmax2=1);\n",
    "imshow_pair(tv[bb,2,50:300,10+250:10+400], tv[bb,3,50:300,10+250:10+400]);\n",
    "tt=tv_loss_r(logits[:,:,50:300,10+250:10+400], labels[:,:,50:300,10+250:10+400])\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(tv[1,2], probs[1,2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = compute_tv(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_tv = compute_tv(100*labels_oh.float(), labels)\n",
    "tv[perfect_tv>0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = torch.div(tv, probs+1e-6)\n",
    "tv.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(tv[1,2], probs[1,2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits = torch.cat([-100*torch.ones(labels.shape), logits_pre], dim=1)\n",
    "probs = torch.nn.Softmax(dim=1)(logits)\n",
    "labels_oh = torch.cat([labels==0, labels==1, labels==2, labels==3], dim=1).long()\n",
    "complement = 1-labels_oh\n",
    "\n",
    "foreground = torch.cat([labels!=0, labels!=0, labels!=0, labels!=0], dim=1).long()\n",
    "background = torch.cat([labels==0, labels==0, labels==0, labels==0], dim=1).long()\n",
    "\n",
    "probs.shape, labels.shape, labels_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_filtered = torch.mul(probs, labels_oh)\n",
    "# probs_filtered = torch.mul(probs, foreground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(labels_oh[1,2], labels_oh[1,3], vmin1=0,vmax1=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(probs[1,2], probs_filtered[1,2], vmin1=0,vmax1=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(probs[1,3], probs_filtered[1,3], vmin1=0,vmax1=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(labels_oh[1,2,0:150,250:400], labels_oh[1,3,0:150,250:400], vmin1=0,vmax1=1);\n",
    "imshow_pair(probs_filtered[1,2,0:150,250:400], probs_filtered[1,3,0:150,250:400], vmin1=0,vmax1=1, vmin2=0,vmax2=1);\n",
    "imshow_pair(tv[1,2,0:150,250:400], tv[1,3,0:150,250:400], vmin1=0,vmax1=1, vmin2=0,vmax2=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(probs_filtered[1,2,250:450,250:500],labels_oh[1,2,250:450,250:500]);\n",
    "imshow_pair(probs_filtered[1,2,250:450,250:500],tv[1,2,250:450,250:500]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(probs_filtered[1,3,250:450,250:500],labels_oh[1,3,250:450,250:500],vmin1=0,vmax1=1,vmin2=0,vmax2=1);\n",
    "imshow_pair(probs_filtered[1,3,250:450,250:500],tv[1,3,250:450,250:500],vmin1=0,vmax1=1,vmin2=0,vmax2=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:polyps] *",
   "language": "python",
   "name": "conda-env-polyps-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
