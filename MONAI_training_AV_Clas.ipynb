{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imsave, imread\n",
    "from skimage import img_as_ubyte, img_as_float\n",
    "import sys\n",
    "import monai, torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_pair(im, gdt, vmin1=None, vmax1=None, vmin2=None, vmax2=None):\n",
    "    f, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "    np_im = np.asarray(im)\n",
    "    np_gdt = np.asarray(gdt)\n",
    "    if len(np_im.shape) == 2:\n",
    "        if vmin1==None:\n",
    "            ax[0].imshow(np_im, cmap='gray'),  ax[0].axis('off')\n",
    "        else:\n",
    "            ax[0].imshow(np_im, cmap='gray', vmin=vmin1, vmax=vmax1),  ax[0].axis('off')\n",
    "    else:\n",
    "        ax[0].imshow(np_im),  ax[0].axis('off')\n",
    "    if len(np_gdt.shape) == 2:\n",
    "        if vmin2==None:\n",
    "            ax[1].imshow(np.asarray(gdt), cmap = 'gray', vmin=vmin2, vmax=vmax2), ax[1].axis('off')\n",
    "        else:\n",
    "            ax[1].imshow(np.asarray(gdt), cmap = 'gray'), ax[1].axis('off')\n",
    "    else:\n",
    "        ax[1].imshow(np.asarray(gdt)), ax[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_masks_old = '../CURRICULUM_AV/data/DRIVE/mask'\n",
    "# path_masks = 'data_new/DRIVE/AV_groundTruth/training/masks/'\n",
    "\n",
    "# mask_names = os.listdir(path_masks_old)\n",
    "\n",
    "# mask_names = sorted([os.path.join(path_masks_old, n) for n in mask_names])\n",
    "\n",
    "# from skimage import io\n",
    "# for m in mask_names:\n",
    "#     mm=io.imread(m)\n",
    "#     io.imsave(m.replace(path_masks_old, path_masks).replace('gif','png'), mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ims = 'data_new/DRIVE/AV_groundTruth/training/images/'\n",
    "path_segs = 'data_new/DRIVE/AV_groundTruth/training/av/'\n",
    "path_masks = 'data_new/DRIVE/AV_groundTruth/training/masks/'\n",
    "\n",
    "img_names = os.listdir(path_ims)\n",
    "seg_names = os.listdir(path_segs)\n",
    "mask_names = os.listdir(path_masks)\n",
    "\n",
    "img_names = sorted([os.path.join(path_ims, n) for n in img_names])\n",
    "seg_names = sorted([os.path.join(path_segs, n) for n in seg_names])\n",
    "mask_names = sorted([os.path.join(path_masks, n) for n in mask_names if not n.startswith('.')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_names = img_names[:16]\n",
    "val_img_names = img_names[16:]\n",
    "\n",
    "train_seg_names = seg_names[:16]\n",
    "val_seg_names = seg_names[16:]\n",
    "\n",
    "train_mask_names = mask_names[:16]\n",
    "val_mask_names = mask_names[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_keys = ('img', 'seg')  # filename keys for image and seg files\n",
    "train_filenames = [{'img': x, 'seg': y, 'mask': m} for x,y,m in zip(train_img_names, train_seg_names, \n",
    "                                                                  train_mask_names)]\n",
    "\n",
    "val_filenames = [{'img': x, 'seg': y, 'mask': m} for x,y,m in zip(val_img_names, val_seg_names, val_mask_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import MapTransform\n",
    "\n",
    "# for type hinting at this stage we need more\n",
    "from monai.config import KeysCollection\n",
    "from typing import Optional, Any, Mapping, Hashable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from monai.metrics import DiceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "dice_metric = DiceMetric(mutually_exclusive=True, to_onehot_y=True, reduction='none', include_background=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "\n",
    "def evaluate(logits, labels):\n",
    "    all_targets = []\n",
    "    all_probs_0 = []\n",
    "    all_probs_1 = []\n",
    "    all_probs_2 = []\n",
    "    all_probs_3 = []\n",
    "\n",
    "    for i in range(len(logits)):\n",
    "        probs = torch.nn.Softmax(dim=0)(logits[i]).detach().cpu().numpy()\n",
    "        all_probs_0.extend(probs[0].ravel())\n",
    "        all_probs_1.extend(probs[1].ravel())\n",
    "        all_probs_2.extend(probs[2].ravel())\n",
    "        all_probs_3.extend(probs[3].ravel())\n",
    "\n",
    "        target = labels[i].numpy()\n",
    "\n",
    "        all_targets.append(target.ravel())\n",
    "\n",
    "    all_probs_np = np.stack([all_probs_0, all_probs_1, all_probs_2, all_probs_3], axis=1)\n",
    "    all_preds_np = np.argmax(all_probs_np, axis=1)\n",
    "    all_targets_np = np.hstack(all_targets)\n",
    "\n",
    "    return f1_score(all_targets_np, all_preds_np,average='weighted'), mcc(all_targets_np, all_preds_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets\n",
    "\n",
    "With a data source and transforms defined we can now create a dataset object. The base class for MONAI is `Dataset`, created here to load the image files only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import Compose, LambdaD, LoadImageD, ToTensorD, ScaleIntensityD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(av):\n",
    "    labels=np.zeros_like(av[0,:,:])\n",
    "    arteries=av[0,:,:]==255\n",
    "    uncertain=av[1,:,:]==255\n",
    "    veins=av[2,:,:]==255 \n",
    "    \n",
    "    labels[uncertain]=0    \n",
    "    labels[arteries]=2\n",
    "    labels[veins]=1 # veins are darker\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "trans = Compose(\n",
    "    [\n",
    "        LoadImageD(keys=('img', 'seg')),\n",
    "#         ScaleIntensityD(keys=('img',)),\n",
    "        LambdaD(('img',), lambda x: x/255.),  # apply gamma only on image\n",
    "        LambdaD(('seg',), to_labels),  # apply gamma only on image\n",
    "    ]\n",
    ")\n",
    "\n",
    "imgd = trans(train_filenames[0])\n",
    "img = imgd[\"img\"]\n",
    "seg = imgd[\"seg\"]\n",
    "img.shape, seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f=imshow_pair(img.transpose(1, 2, 0), seg)\n",
    "# f.savefig('wtf.png')\n",
    "# plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import CacheDataset, Dataset, PersistentDataset\n",
    "from monai.inferers import sliding_window_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai.data import Dataset, ArrayDataset\n",
    "\n",
    "from monai.transforms import Compose, LambdaD, LoadImageD, ToTensorD, AddChannelD, AsChannelFirstD, \\\n",
    "                            RandSpatialCropD, RandRotated, CastToTypeD, SqueezeDimD, ResizeD, \\\n",
    "                            ScaleIntensityD, RandAdjustContrastD, RandRotateD, RandAffineD, \\\n",
    "                            Rand2DElasticD, RandFlipD, RandZoomD, CropForegroundd, ResizeWithPadOrCropD, \\\n",
    "                            DeleteItemsd, NormalizeIntensityD, ScaleIntensityRangeD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImageD(keys=('img', 'seg', 'mask')),\n",
    "        LambdaD(('seg',), to_labels),\n",
    "        AddChannelD(keys=('seg','mask')),\n",
    "        CropForegroundd(keys=('img','seg'), source_key='mask'),\n",
    "        DeleteItemsd(keys=('mask')),\n",
    "        ResizeD(keys=('img','seg'), spatial_size=(512,512), mode=('bicubic', 'nearest'), \n",
    "                align_corners=(False,None)),                   \n",
    "        RandAdjustContrastD(keys=('img',), prob=0.25, gamma=(0.75, 1.25)),\n",
    "        RandRotated(keys=('img','seg'), range_x=45.0,padding_mode='zeros', prob=1.0),\n",
    "        RandFlipD(keys=('img','seg'), prob=0.5, spatial_axis=(0,)), # vertical flip\n",
    "        RandFlipD(keys=('img','seg'), prob=0.5, spatial_axis=(1,)), # horizontal flip\n",
    "#         RandSpatialCropD(keys=('img','seg'), roi_size=(256,256), random_size=False),     \n",
    "        LambdaD(('img',), lambda x: x/255.), \n",
    "#         NormalizeIntensityD(keys=('img',),channel_wise=False),\n",
    "        ToTensorD(keys=('img', 'seg')),\n",
    "        CastToTypeD(keys=('seg',), dtype=torch.long),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# train_ds = Dataset(train_filenames, train_transforms)\n",
    "# train_loader_monai = torch.utils.data.DataLoader(train_ds, batch_size=2, shuffle=False, num_workers=2,)\n",
    "\n",
    "# x, xx = train_ds[0], next(iter(train_loader_monai))\n",
    "# x['img'].min(), x['img'].max(), xx['img'].min(), xx['img'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImageD(keys=('img', 'seg', 'mask')),\n",
    "        LambdaD(('seg',), to_labels),\n",
    "        AddChannelD(keys=('seg','mask')),\n",
    "        CropForegroundd(keys=('img','seg','mask'), source_key='mask'),   \n",
    "        DeleteItemsd(keys=('mask')),\n",
    "        ResizeD(keys=('img','seg'), spatial_size=(512,512), mode=('bicubic', 'nearest'), \n",
    "                align_corners=(False,None)),\n",
    "#         ResizeWithPadOrCropD(keys=('img','seg'), spatial_size=(512,512)),     \n",
    "        LambdaD(('img',), lambda x: x/255.),\n",
    "#         NormalizeIntensityD(keys=('img',),channel_wise=False),\n",
    "        ToTensorD(keys=('img', 'seg')),\n",
    "        CastToTypeD(keys=('seg'), dtype=torch.long),\n",
    "    ]        \n",
    ")\n",
    "\n",
    "val_ds = Dataset(val_filenames, val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(train_filenames, train_transforms)\n",
    "val_ds = Dataset(val_filenames, val_transforms)\n",
    "\n",
    "train_loader_monai = torch.utils.data.DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4,)\n",
    "val_loader_monai = torch.utils.data.DataLoader(val_ds, batch_size=4, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from utils.get_loaders import get_train_val_loaders\n",
    "\n",
    "# train_loader, val_loader = get_train_val_loaders(csv_path_train='data/DRIVE/train_av.csv', \n",
    "#                                                  csv_path_val='data/DRIVE/val_av.csv', batch_size=4,\n",
    "#                                                  tg_size=(512,512), label_values=[0, 85, 170, 255], \n",
    "#                                                  num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # x = next(iter(train_loader))\n",
    "# # print(x[0].min(), x[0].max())\n",
    "# xx = next(iter(train_loader_monai))\n",
    "# xx['img'].min(), xx['img'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inputs = val_ds[0]\n",
    "# inputs['img'].shape, inputs['img'].dtype, inputs['seg'].shape, inputs['seg'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs = train_ds[1]\n",
    "im, tg = inputs['img'], inputs['seg']\n",
    "imshow_pair(im.permute(1,2,0), tg[0])\n",
    "tg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inputs = val_ds[0]\n",
    "# im, tg = inputs['img'], inputs['seg']\n",
    "# imshow_pair(im.permute(1,2,0), tg[0])\n",
    "# im.dtype, tg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "# root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "# print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_t, x_v=next(iter(train_loader_monai)), next(iter(val_loader_monai))\n",
    "x_t['seg'].shape,  x_v['seg'].shape, torch.unique(x_v['seg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x_t, x_v = next(iter(train_loader)), next(iter(val_loader))\n",
    "# x_t[1].shape, x_v[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from monai.networks.nets import UNet\n",
    "# from monai.networks.layers import Norm\n",
    "\n",
    "# model = UNet(\n",
    "#         dimensions=2,\n",
    "#         in_channels=3,\n",
    "#         out_channels=n_classes,\n",
    "#         channels=(8,16,32,64),\n",
    "#         strides=(1, 1, 1, 1),\n",
    "#         num_res_units=4,\n",
    "#         norm=Norm.BATCH,\n",
    "#     ).to(device)\n",
    "\n",
    "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "# params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from models.res_unet_adrian import UNet as unet\n",
    "\n",
    "class Wnet(torch.nn.Module):\n",
    "    def __init__(self, n_classes=1, in_c=3, layers=(8, 16, 32), conv_bridge=True, shortcut=True, mode='train'):\n",
    "        super(Wnet, self).__init__()\n",
    "        self.mode=mode\n",
    "        self.unet1 = unet(in_c=in_c, n_classes=n_classes, layers=layers, conv_bridge=conv_bridge, shortcut=shortcut)\n",
    "        self.unet2 = unet(in_c=in_c+n_classes, n_classes=n_classes, layers=layers, conv_bridge=conv_bridge, shortcut=shortcut)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.unet1(x)\n",
    "        x2 = self.unet2(torch.cat([x, x1], dim=1))\n",
    "        if self.mode!='train':\n",
    "            return x2\n",
    "        return x1,x2\n",
    "\n",
    "model = Wnet(in_c=3, n_classes=n_classes, layers=[8,16,32])\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "model.to(device);\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cycle_lens = [20, 50]\n",
    "grad_acc_steps=0\n",
    "n_cycles = cycle_lens[0]\n",
    "min_lr = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if len(cycle_lens)==2: # handles option of specifying cycles as pair (n_cycles, cycle_len)\n",
    "    cycle_lens = cycle_lens[0]*[cycle_lens[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from models.get_model import get_arch\n",
    "# model = get_arch('big_wnet', in_c=3, n_classes=n_classes)\n",
    "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "# params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# model.to(device);\n",
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 1e-2)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                              T_max=cycle_lens[0] * len(train_loader_monai) // (grad_acc_steps + 1), \n",
    "                              eta_min=min_lr)\n",
    "setattr(scheduler, 'cycle_lens', cycle_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t=next(iter(train_loader_monai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(x_t['img'].to(device))\n",
    "logits_aux, logits = logits[0].cpu(), logits[1].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = x_t['seg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape, torch.unique(labels), logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_new = torch.cat([-10*torch.ones(labels.shape), logits], dim=1)\n",
    "logits_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_new.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(logits_new, labels.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt = labels[labels!=0]-1\n",
    "# logits[labels!=0].shape, tt.shape\n",
    "# torch.unique(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.BCEWithLogitsLoss()(tt.float()-1,logits[labels!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.BCEWithLogitsLoss()(labels[labels!=0].float()-1,logits[labels!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels.shape, torch.unique(labels), logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt = labels[labels!=0]-1\n",
    "# pp = logits[labels!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -(tt*torch.nn.functional.logsigmoid(pp) + (1-tt)*torch.nn.functional.logsigmoid(1-pp)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_bce_no_back(logits, labels):\n",
    "#     tt = labels[labels!=0]-1\n",
    "#     pp = logits[labels!=0]\n",
    "#     return -(tt*torch.nn.functional.logsigmoid(pp) + (1-tt)*torch.nn.functional.logsigmoid(1-pp)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_bce_no_back(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = compute_bce_no_back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What would be better:\n",
    "Predict two classes, add a channel that has all -100 in the first place, it acts as our prediction of the background. Then we use torch.nn.CrossEntropy(ignore_index=0) and can safely use Softmax and monai.dice with ignore_background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_one_epoch(loader, model, criterion, optimizer=None, scheduler=None,\n",
    "                  grad_acc_steps=0, assess=False, save_plot=False, cycle=0):\n",
    "    device='cuda' if next(model.parameters()).is_cuda else 'cpu'\n",
    "    train = optimizer is not None  # if we are in training mode there will be an optimizer and train=True here\n",
    "\n",
    "    if train: model.train()\n",
    "    else: \n",
    "        model.eval()\n",
    "        model.mode='val'\n",
    "        \n",
    "    if assess: dice, auc = 0, 0\n",
    "    n_elems, running_loss = 0, 0\n",
    "    wnet=False\n",
    "    for i_batch, batch_data in enumerate(loader):\n",
    "        try:\n",
    "            inputs, labels = (batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device), )\n",
    "        except:\n",
    "            inputs, labels = batch_data[0].to(device), batch_data[1].unsqueeze(dim=1).to(device)\n",
    "            \n",
    "        if train:  # only in training mode               \n",
    "            logits = model(inputs)\n",
    "            if isinstance(logits, tuple): # wnet\n",
    "                wnet=True\n",
    "                logits_aux, logits = logits\n",
    "                loss_aux = criterion(torch.cat([-10*torch.ones(labels.shape).to(device), logits_aux], dim=1), \n",
    "                                     labels.squeeze(dim=1))                \n",
    "#             loss = criterion(logits, labels.squeeze(dim=1))\n",
    "#             loss = compute_bce_no_back(logits, labels)\n",
    "            loss = criterion(torch.cat([-10*torch.ones(labels.shape).to(device), logits], dim=1), \n",
    "                             labels.squeeze(dim=1))\n",
    "\n",
    "        \n",
    "        \n",
    "            if wnet:\n",
    "                loss+=loss_aux\n",
    "                \n",
    "            (loss / (grad_acc_steps + 1)).backward()\n",
    "            if i_batch % (grad_acc_steps+1) == 0:  # for grad_acc_steps=0, this is always True\n",
    "                optimizer.step()\n",
    "                for _ in range(grad_acc_steps+1): scheduler.step() # for grad_acc_steps=0, this means once\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        else:\n",
    "#             logits = sliding_window_inference(inputs, roi_size=(256,256), \n",
    "#                                               sw_batch_size=loader.batch_size, \n",
    "#                                               predictor=model)\n",
    "            logits = model(inputs)\n",
    "            if isinstance(logits, tuple): # wnet\n",
    "                wnet=True\n",
    "                logits_aux, logits = logits\n",
    "#                 loss_aux = criterion(logits_aux, labels.squeeze(dim=1))\n",
    "                loss_aux = criterion(torch.cat([-10*torch.ones(labels.shape).to(device), logits_aux], dim=1), \n",
    "                                     labels)\n",
    "#             loss = criterion(logits, labels.squeeze(dim=1))\n",
    "            loss = criterion(torch.cat([-10*torch.ones(labels.shape).to(device), logits], dim=1), \n",
    "                             labels.squeeze(dim=1))\n",
    "            if wnet:\n",
    "                loss+=loss_aux\n",
    "\n",
    "            if assess:\n",
    "                \n",
    "                dice = dice_metric(torch.cat([-10*torch.ones(labels.shape).to(device), logits], dim=1), labels)\n",
    "                \n",
    "                auc=dice[:,1].mean()\n",
    "                dice=dice[:,0].mean()\n",
    "                \n",
    "                if save_plot:\n",
    "                    preds = logits.sigmoid().squeeze()\n",
    "                    back=labels==0\n",
    "                    preds[back.squeeze()]=0.5\n",
    "                    for j in range(logits.shape[0]):\n",
    "                        im_name = batch_data['img_meta_dict']['filename_or_obj'][j].split('/')[-1].split('.')[-2]\n",
    "                        s_name = 'logs/displays/{}_cycle_{}.png'.format(im_name, cycle)\n",
    "                        f=imshow_pair(preds[j].cpu(), labels[j].squeeze().cpu())\n",
    "#                         f.savefig(s_name)\n",
    "#                         plt.close(f)\n",
    "\n",
    "        # Compute running loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        n_elems += inputs.size(0)\n",
    "        run_loss = running_loss / n_elems\n",
    "            \n",
    "    if assess: return dice, auc, run_loss\n",
    "    return None, None, run_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import compute_roc_auc, compute_meandice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_one_cycle(train_loader, model, criterion, optimizer=None, scheduler=None, grad_acc_steps=0, cycle=0):\n",
    "    # prepare next cycle:\n",
    "    # reset iteration counter\n",
    "    scheduler.last_epoch = -1\n",
    "    # update number of iterations\n",
    "\n",
    "    scheduler.T_max = scheduler.cycle_lens[cycle] * len(train_loader)\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    cycle_len = scheduler.cycle_lens[cycle]\n",
    "    with trange(cycle_len) as t:\n",
    "        for epoch in range(cycle_len):\n",
    "            if epoch == cycle_len-1: assess=True # only compute performance on last epoch\n",
    "            else: assess = False\n",
    "                \n",
    "            dice, auc, tr_loss = run_one_epoch(train_loader, model, criterion, optimizer=optimizer,\n",
    "                                                          scheduler=scheduler, grad_acc_steps=grad_acc_steps, \n",
    "                                                          assess=assess, cycle=cycle)\n",
    "            t.set_postfix_str(\"Cycle: {}/{} Ep. {}/{} -- tr. loss={:.4f} / lr={:.6f}\".format(cycle+1, \n",
    "                                                                                    len(scheduler.cycle_lens),\n",
    "                                                                                    epoch+1, cycle_len,\n",
    "                                                                                    float(tr_loss), \n",
    "                                                                                    get_lr(optimizer)))\n",
    "            t.update()\n",
    "            \n",
    "    return dice, auc, tr_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MONAI LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "dice_metric = DiceMetric(sigmoid=True, \n",
    "                         logit_thresh=0.5,\n",
    "                         to_onehot_y=True,\n",
    "                         reduction='none', \n",
    "                         include_background=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cycle in range(12):\n",
    "    \n",
    "    _, _, _  = train_one_cycle(train_loader_monai,model, criterion, optimizer,scheduler,cycle=cycle)\n",
    "\n",
    "    save_plot = (cycle+1)%5==0\n",
    "    save_plot=False\n",
    "    with torch.no_grad():\n",
    "        vl_dice, vl_auc, vl_loss = run_one_epoch(val_loader_monai, model, \n",
    "                                                                  criterion, \n",
    "                                                                 optimizer=None, scheduler=None,\n",
    "                                                                 grad_acc_steps=0, assess=True, \n",
    "                                                                 save_plot=save_plot, cycle=cycle)\n",
    "#         # Assess also on traininig data but with val transforms\n",
    "#         val_data = val_loader.dataset.data.copy()\n",
    "#         val_loader.dataset.data = train_loader.dataset.data\n",
    "#         tr_d_bck, tr_d_arts, tr_d_veins, tr_f1, tr_mcc, tr_loss = run_one_epoch(val_loader, model, criterion, \n",
    "#                                                                  optimizer=None, scheduler=None,\n",
    "#                                                                  grad_acc_steps=0, assess=True, \n",
    "#                                                                  save_plot=save_plot, cycle=cycle)\n",
    "#         val_loader.dataset.data = val_data\n",
    "\n",
    "        tr_dice, tr_auc, tr_loss = run_one_epoch(train_loader_monai, model, criterion, \n",
    "                                                                 optimizer=None, scheduler=None,\n",
    "                                                                 grad_acc_steps=0, assess=True, \n",
    "                                                                 save_plot=save_plot, cycle=cycle)\n",
    "        \n",
    "        \n",
    "        print('Train/Val Loss: {:.4f}/{:.4f} -- DICE|AUC: {:.4f}/{:.4f} | {:.4f}/{:.4f}'.\\\n",
    "              format(tr_loss, vl_loss,tr_dice, vl_dice,tr_auc, vl_auc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "#     vl_dice, vl_auc, vl_loss\n",
    "    logits, labels = run_one_epoch(val_loader_monai, model, criterion, optimizer=None, scheduler=None,\n",
    "                                                             grad_acc_steps=0, assess=True, save_plot=True, cycle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([-10*torch.ones(labels.shape).to(device), logits], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "dice_metric = DiceMetric(sigmoid=True, \n",
    "                         logit_thresh=0.5,\n",
    "                         to_onehot_y=True,\n",
    "                         reduction='none', \n",
    "                         include_background=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = dice_metric(torch.cat([-10*torch.ones(labels.shape).to(device), logits], dim=1), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[:,0].mean(), dd[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV LOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_arch('wnet', in_c=3, n_classes=n_classes)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "model.to(device);\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 1e-2)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                              T_max=cycle_lens[0] * len(train_loader) // (grad_acc_steps + 1), \n",
    "                              eta_min=min_lr)\n",
    "setattr(scheduler, 'cycle_lens', cycle_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cycle in range(10):\n",
    "    \n",
    "    _, _, _, _, _, _ = train_one_cycle(train_loader,model, criterion, optimizer,scheduler,cycle=cycle)\n",
    "\n",
    "    save_plot = (cycle+1)%5==0\n",
    "    save_plot=False\n",
    "    with torch.no_grad():\n",
    "        vl_d_bck, vl_d_arts, vl_d_veins, vl_f1, vl_mcc, vl_loss = run_one_epoch(val_loader, model, criterion, \n",
    "                                                                 optimizer=None, scheduler=None,\n",
    "                                                                 grad_acc_steps=0, assess=True, \n",
    "                                                                 save_plot=save_plot, cycle=cycle)\n",
    "#         # Assess also on traininig data but with val transforms\n",
    "#         val_data = val_loader.dataset.data.copy()\n",
    "#         val_loader.dataset.data = train_loader.dataset.data\n",
    "#         tr_d_bck, tr_d_arts, tr_d_veins, tr_f1, tr_mcc, tr_loss = run_one_epoch(val_loader, model, criterion, \n",
    "#                                                                  optimizer=None, scheduler=None,\n",
    "#                                                                  grad_acc_steps=0, assess=True, \n",
    "#                                                                  save_plot=save_plot, cycle=cycle)\n",
    "#         val_loader.dataset.data = val_data\n",
    "\n",
    "        tr_d_bck, tr_d_arts, tr_d_veins, tr_f1, tr_mcc, tr_loss = run_one_epoch(train_loader, model, criterion, \n",
    "                                                                 optimizer=None, scheduler=None,\n",
    "                                                                 grad_acc_steps=0, assess=True, \n",
    "                                                                 save_plot=save_plot, cycle=cycle)\n",
    "        \n",
    "        \n",
    "        print('Train/Val Loss: {:.4f}/{:.4f} -- '\\\n",
    "              'per-class Train/Val DICE: {:.4f}/{:.4f} | {:.4f}/{:.4f} | {:.4f}/{:.4f}'.format(tr_loss, vl_loss,\n",
    "                                                                                     tr_d_bck, vl_d_bck,\n",
    "                                                                                     tr_d_arts, vl_d_arts,\n",
    "                                                                                     tr_d_veins, vl_d_veins))\n",
    "        print('Train/Val F1|MCC: {:.4f}/{:.4f} | {:.4f}/{:.4f}'.format(tr_f1, vl_f1, tr_mcc, vl_mcc))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:polyps] *",
   "language": "python",
   "name": "conda-env-polyps-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
